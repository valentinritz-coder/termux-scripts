cp -f ~/src/llama.cpp/build/bin/llama-server $PREFIX/bin/
chmod +x $PREFIX/bin/llama-server
which llama-server
---
llama-server \
  -m /sdcard/cfl_watch/models/qwen2.5-0.5b-instruct-q4_k_m.gguf \
  --host 127.0.0.1 --port 8000 \
  -c 2048 -t 4 \
  --alias local-model
----
curl -sS http://127.0.0.1:8000/v1/models | head
----
cd ~/cfl_watch
export OPENAI_BASE_URL=http://127.0.0.1:8000
export OPENAI_API_KEY=dummy
export LLM_MODEL=local-model
export SNAP_MODE=3

bash tools/llm_explore.sh "Ouvre CFL, cherche un trajet Luxembourg -> Arlon"

----

touch /sdcard/cfl_watch/STOP
